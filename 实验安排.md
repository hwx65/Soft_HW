## Experiment Arrangement

### 1. Dataset

We attempt to mine issues from GitHub projects to collect bugs. Issues are natural language descriptions of bugs in the program, which are written by developers. The projects we used in our experiment are mainly based on WeChat mini programs. Finally, we plan to collect bugs from 10,00 projects. We perform data cleaning and manually classify bugs into different categories.

### 2. Research Questions

- **RQ1: ** How many categories should bugs be divided into?

  We divide bugs into 9 categories, and mark all invalid bugs as 0. Bugs are divided into the following categories：

  - Conceptual error: These bugs are a developer's misunderstanding of what the software must do.
  - Arithmetic bug: Some numerical calculation errors, such as division by zero, arithmetic overflow or underflow, and loss of arithmetic precision due to rounding or numerically unstable algorithms.
  - Logic bug: Logical bug is a kind of bug that makes the application work incorrectly. It doesn't lead to crashes. This kind of bugs is difficult to find.
  - Syntax bug: Syntax bug is an error in the system code of the application. It’s a small grammatical mistake, can be in one symbol. Compiler provides information about such bugs when the code is compiled, the developer can fix them quickly.
  - Resource bug: Resource bug is a common type. For example, null pointer dereference, access violations, resource leaks, buffer overflow and so on.
  - Multi-threading programming bug: Deadlock, race condition and concurrency errors are all multi-threading  bugs. Race condition bugs may occur when programs have multiple components executing at the same time. 
  - Interfacing bug: This category of bugs is always caused by incorrect API usage, protocol implementation, hardware handling or some other related errors.
  - Performance bug: Performance bugs are programming errors that cause performance degradation and lead to poor user experience and low system throughput.
  - Teamworking bug: Some mistakes made by programmers in the development process, such as unpropagated updates, and differences between documentation and product.

- **RQ2：**Which classification algorithm has better prediction results? 

  We compare four state-of-the-art classification algorithms. 

### 3. Expected Outcomes

We conduct our experiment using MacBook Pro with 2.3 GHz Intel Core i5 processor and 8 GB RAM. We expect the accuracy of our classification model to reach over 97%. 

